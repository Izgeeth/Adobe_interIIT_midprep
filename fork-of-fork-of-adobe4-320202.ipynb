{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9526829,"sourceType":"datasetVersion","datasetId":5801331},{"sourceId":9548807,"sourceType":"datasetVersion","datasetId":5817858},{"sourceId":9555976,"sourceType":"datasetVersion","datasetId":5822842},{"sourceId":9562808,"sourceType":"datasetVersion","datasetId":5827752}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:29:29.207149Z","iopub.execute_input":"2024-10-10T10:29:29.207471Z","iopub.status.idle":"2024-10-10T10:29:30.220472Z","shell.execute_reply.started":"2024-10-10T10:29:29.207440Z","shell.execute_reply":"2024-10-10T10:29:30.219592Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/adobetraindata/behaviour_simulation_train.csv'\ntest_path = '/kaggle/input/inter-iit-mid-prep-adobe/problem_1_test_dataset/behaviour_simulation_test_company.xlsx'","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:29:30.222314Z","iopub.execute_input":"2024-10-10T10:29:30.222731Z","iopub.status.idle":"2024-10-10T10:29:30.226831Z","shell.execute_reply.started":"2024-10-10T10:29:30.222697Z","shell.execute_reply":"2024-10-10T10:29:30.226016Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"test_dataset = pd.read_excel(test_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:29:30.227818Z","iopub.execute_input":"2024-10-10T10:29:30.228063Z","iopub.status.idle":"2024-10-10T10:29:32.960541Z","shell.execute_reply.started":"2024-10-10T10:29:30.228034Z","shell.execute_reply":"2024-10-10T10:29:32.959474Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test_dataset.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:29:32.964367Z","iopub.execute_input":"2024-10-10T10:29:32.964750Z","iopub.status.idle":"2024-10-10T10:29:33.001841Z","shell.execute_reply.started":"2024-10-10T10:29:32.964716Z","shell.execute_reply":"2024-10-10T10:29:33.000935Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000 entries, 0 to 9999\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   id                10000 non-null  int64 \n 1   date              10000 non-null  object\n 2   content           10000 non-null  object\n 3   username          10000 non-null  object\n 4   media             10000 non-null  object\n 5   inferred company  10000 non-null  object\ndtypes: int64(1), object(5)\nmemory usage: 468.9+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = pd.read_csv(train_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:29:33.002977Z","iopub.execute_input":"2024-10-10T10:29:33.003353Z","iopub.status.idle":"2024-10-10T10:29:37.635070Z","shell.execute_reply.started":"2024-10-10T10:29:33.003312Z","shell.execute_reply":"2024-10-10T10:29:37.634256Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:29:37.832611Z","iopub.execute_input":"2024-10-10T10:29:37.832896Z","iopub.status.idle":"2024-10-10T10:29:37.842992Z","shell.execute_reply.started":"2024-10-10T10:29:37.832865Z","shell.execute_reply":"2024-10-10T10:29:37.842013Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"Photo_data = train_dataset[train_dataset['media'].apply(lambda x: x.startswith('[Photo'))].copy().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:29:37.855385Z","iopub.execute_input":"2024-10-10T10:29:37.855757Z","iopub.status.idle":"2024-10-10T10:29:38.063565Z","shell.execute_reply.started":"2024-10-10T10:29:37.855697Z","shell.execute_reply":"2024-10-10T10:29:38.062648Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"img_links = Photo_data['media'].apply(lambda x:x.split(\"Photo(previewUrl\")[1].split(\"'\")[1])","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:29:38.064644Z","iopub.execute_input":"2024-10-10T10:29:38.065634Z","iopub.status.idle":"2024-10-10T10:29:38.279105Z","shell.execute_reply.started":"2024-10-10T10:29:38.065601Z","shell.execute_reply":"2024-10-10T10:29:38.278100Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('/kaggle/input/image-data-adobe/image_data.pkl','rb') as f:\n    image_data = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:29:38.280415Z","iopub.execute_input":"2024-10-10T10:29:38.280808Z","iopub.status.idle":"2024-10-10T10:31:30.225449Z","shell.execute_reply.started":"2024-10-10T10:29:38.280762Z","shell.execute_reply":"2024-10-10T10:31:30.224606Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:31:30.226581Z","iopub.execute_input":"2024-10-10T10:31:30.226886Z","iopub.status.idle":"2024-10-10T10:31:30.231203Z","shell.execute_reply.started":"2024-10-10T10:31:30.226853Z","shell.execute_reply":"2024-10-10T10:31:30.230328Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"valid_idxs = []\nfor i,_ in enumerate(image_data):\n    if _ is not None:\n        valid_idxs.append(i)\nPhoto_data = Photo_data.iloc[valid_idxs].reset_index(drop=True)\nimage_data = np.array(image_data)[valid_idxs]\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:31:30.232424Z","iopub.execute_input":"2024-10-10T10:31:30.232706Z","iopub.status.idle":"2024-10-10T10:31:30.531418Z","shell.execute_reply.started":"2024-10-10T10:31:30.232675Z","shell.execute_reply":"2024-10-10T10:31:30.530418Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Define custom bins\nbins = [0, 100, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000, 500000]\nlabels = ['0-100', '101-500', '501-1k', '1k-2k', '2k-5k', '5k-10k', '10k-20k', '20k-50k', '50k-100k', '100k+']\n\n# Bin the likes into categories\nPhoto_data['likes_binned'] = pd.cut(Photo_data['likes'], bins=bins, labels=labels, include_lowest=True)\n\n# Convert bin labels to numeric categories\nle = LabelEncoder()\ny = le.fit_transform(Photo_data['likes_binned'])","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:31:30.535837Z","iopub.execute_input":"2024-10-10T10:31:30.536159Z","iopub.status.idle":"2024-10-10T10:31:31.435106Z","shell.execute_reply.started":"2024-10-10T10:31:30.536126Z","shell.execute_reply":"2024-10-10T10:31:31.434316Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"Photo_data['likes_binned'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:31:31.436228Z","iopub.execute_input":"2024-10-10T10:31:31.436711Z","iopub.status.idle":"2024-10-10T10:31:31.449476Z","shell.execute_reply.started":"2024-10-10T10:31:31.436676Z","shell.execute_reply":"2024-10-10T10:31:31.448329Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"likes_binned\n0-100       124394\n101-500      44644\n501-1k       16248\n1k-2k         9279\n2k-5k         6415\n5k-10k        1991\n10k-20k        934\n20k-50k        623\n50k-100k       101\n100k+           41\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# model = LikesPredictionModel()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:31:31.450794Z","iopub.execute_input":"2024-10-10T10:31:31.451504Z","iopub.status.idle":"2024-10-10T10:31:31.455857Z","shell.execute_reply.started":"2024-10-10T10:31:31.451454Z","shell.execute_reply":"2024-10-10T10:31:31.454800Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# model.load_state_dict(torch.load('/kaggle/input/cnn-adobe/image_likes_model.pth'))","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:31:31.457039Z","iopub.execute_input":"2024-10-10T10:31:31.457371Z","iopub.status.idle":"2024-10-10T10:31:31.467305Z","shell.execute_reply.started":"2024-10-10T10:31:31.457318Z","shell.execute_reply":"2024-10-10T10:31:31.466427Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# len(Photo_data['likes'])","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:31:31.468230Z","iopub.execute_input":"2024-10-10T10:31:31.468602Z","iopub.status.idle":"2024-10-10T10:31:31.478573Z","shell.execute_reply.started":"2024-10-10T10:31:31.468568Z","shell.execute_reply":"2024-10-10T10:31:31.477708Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedGroupKFold,StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:31:31.479719Z","iopub.execute_input":"2024-10-10T10:31:31.480002Z","iopub.status.idle":"2024-10-10T10:31:31.566930Z","shell.execute_reply.started":"2024-10-10T10:31:31.479963Z","shell.execute_reply":"2024-10-10T10:31:31.566176Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"splitter = StratifiedKFold(n_splits=10, random_state = 42,shuffle=True)\nsplit = splitter.split(Photo_data, y)\ntrain_inds, test_inds = next(split)\nPhoto_data_sub, y_sub, image_data_sub = Photo_data.copy().iloc[test_inds].reset_index(drop=True), np.array(y[test_inds]), image_data[test_inds]","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:33:42.549819Z","iopub.execute_input":"2024-10-10T10:33:42.550240Z","iopub.status.idle":"2024-10-10T10:33:42.621425Z","shell.execute_reply.started":"2024-10-10T10:33:42.550199Z","shell.execute_reply":"2024-10-10T10:33:42.620598Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# splitter = StratifiedGroupKFold(n_splits=4, random_state = 42,shuffle=True)\n# split = splitter.split(Photo_data, y,groups=Photo_data['inferred company'])\n# train_inds, test_inds = next(split)\n# # from imblearn.under_sampling import RandomUnderSampler\n# train_images, train_likes = image_data[train_inds], np.array(y[train_inds])\n# # rus = RandomUnderSampler(sampling_strategy='majority',random_state=42)\n# # X_res, y_res = rus.fit_resample(train_images, train_likes)\n# # X_res = X_res.squeeze()\n# # y_res = y_res.squeeze()\n# val_images, val_likes = image_data[test_inds], np.array(y[test_inds])\nsplitter = StratifiedGroupKFold(n_splits=3, random_state = 42,shuffle=True)\nsplit = splitter.split(Photo_data_sub, y_sub,groups=Photo_data_sub['inferred company'])\ntrain_inds, test_inds = next(split)\n# from imblearn.under_sampling import RandomUnderSampler\ntrain_images, train_likes, train_text = image_data_sub[train_inds], np.array(y_sub[train_inds]), Photo_data_sub.iloc[train_inds].reset_index(drop=True)['content']\n# rus = RandomUnderSampler(sampling_strategy='majority',random_state=42)\n# X_res, y_res = rus.fit_resample(train_images, train_likes)\n# X_res = X_res.squeeze()\n# y_res = y_res.squeeze()\nval_images, val_likes, val_text = image_data_sub[test_inds], np.array(y_sub[test_inds]), Photo_data_sub.iloc[test_inds].reset_index(drop=True)['content']","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:45:26.020915Z","iopub.execute_input":"2024-10-10T10:45:26.021345Z","iopub.status.idle":"2024-10-10T10:45:26.310639Z","shell.execute_reply.started":"2024-10-10T10:45:26.021269Z","shell.execute_reply":"2024-10-10T10:45:26.309810Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"len(train_likes)/len(val_likes)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:45:29.215772Z","iopub.execute_input":"2024-10-10T10:45:29.216505Z","iopub.status.idle":"2024-10-10T10:45:29.222829Z","shell.execute_reply.started":"2024-10-10T10:45:29.216466Z","shell.execute_reply":"2024-10-10T10:45:29.221845Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"3.2295928910932012"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport numpy as np\nfrom PIL import Image\nimport io\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom transformers import CLIPProcessor, CLIPModel\n\n# Load CLIP model and processor\nclip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nclip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n\nclass ImageTextLikesDataset(Dataset):\n    def __init__(self, image_data, text_data, likes):\n        self.image_data = image_data\n        self.text_data = text_data\n        self.likes = likes\n    \n    def __len__(self):\n        return len(self.image_data)\n    \n    def __getitem__(self, idx):\n        image = Image.open(io.BytesIO(self.image_data[idx])).convert('RGB')\n        text = self.text_data[idx]\n        return image, text, torch.tensor(self.likes[idx], dtype=torch.long)\n\nclass VLMEmbeddingModel(nn.Module):\n    def __init__(self):\n        super(VLMEmbeddingModel, self).__init__()\n        self.clip = clip_model\n    \n    def forward(self, images, texts):\n        inputs = clip_processor(text=texts, images=images, return_tensors=\"pt\", padding=True, truncation=True)\n        inputs = {k: v.to(self.clip.device) for k, v in inputs.items()}\n        outputs = self.clip(**inputs)\n        image_features = outputs.image_embeds\n        text_features = outputs.text_embeds\n        combined_features = torch.cat((image_features, text_features), dim=1)\n        return combined_features\n\ndef collate_fn(batch):\n    images, texts, likes = zip(*batch)\n    return list(images), list(texts), torch.stack(likes)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:53:11.081234Z","iopub.execute_input":"2024-10-10T10:53:11.082023Z","iopub.status.idle":"2024-10-10T10:53:12.269616Z","shell.execute_reply.started":"2024-10-10T10:53:11.081969Z","shell.execute_reply":"2024-10-10T10:53:12.268573Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, num_epochs=2):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    model.to(device)\n    \n#     for epoch in range(num_epochs):\n#     print(f'Epoch {epoch+1}/{num_epochs} running')\n    model.eval()\n    train_embeddings = []\n    train_likes = []\n    with torch.no_grad():\n        for images, texts, likes in tqdm(train_loader):\n            likes = likes.to(device)\n            outputs = model(images, texts)\n            train_embeddings.append(outputs.detach().cpu().numpy())\n            train_likes.append(likes.cpu().numpy())\n\n    train_embeddings = np.vstack(train_embeddings)\n    train_likes = np.concatenate(train_likes)\n\n    model.eval()\n    val_embeddings = []\n    val_likes = []\n\n    with torch.no_grad():\n        for images, texts, likes in tqdm(val_loader):\n            likes = likes.to(device)\n            outputs = model(images, texts)\n            val_embeddings.append(outputs.detach().cpu().numpy())\n            val_likes.append(likes.cpu().numpy())\n\n    val_embeddings = np.vstack(val_embeddings)\n    val_likes = np.concatenate(val_likes)\n\n    # Train Random Forest on the embeddings\n    rf_classifier = RandomForestClassifier(max_depth=10, class_weight='balanced')\n    rf_classifier.fit(train_embeddings, train_likes)\n\n    train_predictions = rf_classifier.predict(train_embeddings)\n    val_predictions = rf_classifier.predict(val_embeddings)\n\n    train_accuracy = accuracy_score(train_likes, train_predictions)\n    val_accuracy = accuracy_score(val_likes, val_predictions)\n\n    print(f'Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}')\n    \n    return model, rf_classifier","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:53:14.850922Z","iopub.execute_input":"2024-10-10T10:53:14.851779Z","iopub.status.idle":"2024-10-10T10:53:14.862628Z","shell.execute_reply.started":"2024-10-10T10:53:14.851735Z","shell.execute_reply":"2024-10-10T10:53:14.861593Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# Assuming you have these variables: train_images, val_images, train_likes, val_likes, Photo_data\n\ntrain_dataset = ImageTextLikesDataset(train_images, train_text, train_likes)\nval_dataset = ImageTextLikesDataset(val_images, val_text, val_likes)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, collate_fn=collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, collate_fn=collate_fn)\n\n# Initialize the model\nmodel = VLMEmbeddingModel()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T10:53:15.620641Z","iopub.execute_input":"2024-10-10T10:53:15.621380Z","iopub.status.idle":"2024-10-10T10:53:15.627832Z","shell.execute_reply.started":"2024-10-10T10:53:15.621340Z","shell.execute_reply":"2024-10-10T10:53:15.626764Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrained_model, rf_classifier = train_model(model, train_loader, val_loader, num_epochs=2)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-10T10:53:16.725694Z","iopub.execute_input":"2024-10-10T10:53:16.726473Z","iopub.status.idle":"2024-10-10T10:58:10.904954Z","shell.execute_reply.started":"2024-10-10T10:53:16.726431Z","shell.execute_reply":"2024-10-10T10:58:10.903698Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/489 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n 24%|██▍       | 119/489 [00:47<02:25,  2.55it/s]/opt/conda/lib/python3.10/site-packages/PIL/Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n 50%|████▉     | 244/489 [01:35<01:30,  2.70it/s]/opt/conda/lib/python3.10/site-packages/PIL/Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n 94%|█████████▍| 461/489 [02:59<00:10,  2.56it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2e3fd96b90>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n    self._shutdown_workers()  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n\n    if w.is_alive():\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2e3fd96b90>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n    self._shutdown_workers()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n    if w.is_alive():\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\n100%|██████████| 489/489 [03:10<00:00,  2.56it/s]\n  0%|          | 0/152 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n 14%|█▍        | 22/152 [00:09<00:51,  2.53it/s]/opt/conda/lib/python3.10/site-packages/PIL/Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n100%|██████████| 152/152 [01:00<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Accuracy: 0.9129, Val Accuracy: 0.4348\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict_likes(model, rf_classifier, image_dataloader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    all_embeddings = []\n    all_likes = []\n    \n    with torch.no_grad():\n        for images, texts, likes in tqdm(image_dataloader, desc=\"Predicting\"):\n            outputs = model(images, texts)\n            all_embeddings.append(outputs.detach().cpu().numpy())\n            all_likes.append(likes.numpy())\n    \n    all_embeddings = np.vstack(all_embeddings)\n    all_likes = np.concatenate(all_likes)\n    \n    predictions = rf_classifier.predict(all_embeddings)\n    return predictions, all_likes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions\nval_predictions, val_likes = predict_likes(trained_model, rf_classifier, val_loader)\ntrain_predictions, train_likes = predict_likes(trained_model, rf_classifier, train_loader)\n\n# Evaluate the classifier\nval_accuracy = accuracy_score(val_likes, val_predictions)\ntrain_accuracy = accuracy_score(train_likes, train_predictions)\n\nprint(f\"Validation Accuracy: {val_accuracy}\")\nprint(f\"Train Accuracy: {train_accuracy}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import Dataset, DataLoader\n# from torchvision import transforms\n# import numpy as np\n# from PIL import Image\n# import io\n# from sklearn.model_selection import train_test_split\n# import timm\n# from tqdm.auto import tqdm\n# import os\n# from functools import lru_cache\n\n# class OptimizedImageLikesDataset(Dataset):\n#     def __init__(self, image_data, likes, transform=None, cache_size=1000):\n#         self.image_data = np.array(image_data, dtype=object)\n#         self.likes = np.array(likes)\n#         self.transform = transform\n#         self.cache_size = cache_size\n\n#     def __len__(self):\n#         return len(self.likes)\n\n#     @lru_cache(maxsize=1000)\n#     def __getitem__(self, idx):\n#         image = Image.open(io.BytesIO(self.image_data[idx])).convert('RGB')\n#         if self.transform:\n#             image = self.transform(image)\n#         return image, torch.tensor(self.likes[idx], dtype=torch.long)\n\n# def worker_init_fn(worker_id):\n#     worker_info = torch.utils.data.get_worker_info()\n#     dataset = worker_info.dataset\n#     worker_id = worker_info.id\n#     num_workers = worker_info.num_workers\n#     per_worker = len(dataset) // num_workers\n#     dataset.image_data = np.memmap('image_data.memmap', dtype='uint8', mode='r', \n#                                    shape=(len(dataset.likes), len(dataset.image_data[0])),\n#                                    offset=worker_id * per_worker * dataset.image_data[0].nbytes,\n#                                    length=per_worker * dataset.image_data[0].nbytes)\n\n# class LikesPredictionModel(nn.Module):\n#     def __init__(self):\n#         super(LikesPredictionModel, self).__init__()\n#         self.efficientnet = timm.create_model('efficientnet_b0', pretrained=True)\n#         self.fc1 = nn.Linear(1000, 512)\n#         self.dropout = nn.Dropout(0.5)\n#         self.fc2 = nn.Linear(512, 10)\n#         self.bn1 = nn.BatchNorm1d(1000)\n#         self.bn2 = nn.BatchNorm1d(512)\n\n#     def forward(self, x):\n#         x = self.efficientnet(x)\n#         x = torch.relu(self.fc1(self.bn1(self.dropout(torch.relu(x)))))\n#         x = self.bn2(self.dropout(x))\n#         x = self.fc2(x)\n#         return x.squeeze()\n\n# def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=2):\n#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     print(f\"Using device: {device}\")\n#     model.to(device)\n    \n#     for epoch in range(num_epochs):\n#         print(f'Epoch {epoch+1}/{num_epochs}')\n#         model.train()\n#         train_loss = 0.0\n#         train_correct = 0\n#         train_total = 0\n\n#         for images, likes in tqdm(train_loader, desc=\"Training\"):\n#             images, likes = images.to(device), likes.to(device)\n#             optimizer.zero_grad()\n#             outputs = model(images)\n#             loss = criterion(outputs, likes)\n#             loss.backward()\n#             optimizer.step()\n            \n#             train_loss += loss.item()\n#             _, predicted = outputs.max(1)\n#             train_total += likes.size(0)\n#             train_correct += predicted.eq(likes).sum().item()\n\n#         train_loss /= len(train_loader)\n#         train_acc = train_correct / train_total\n        \n#         model.eval()\n#         val_loss = 0.0\n#         val_correct = 0\n#         val_total = 0\n\n#         with torch.no_grad():\n#             for images, likes in tqdm(val_loader, desc=\"Validation\"):\n#                 images, likes = images.to(device), likes.to(device)\n#                 outputs = model(images)\n#                 loss = criterion(outputs, likes)\n                \n#                 val_loss += loss.item()\n#                 _, predicted = outputs.max(1)\n#                 val_total += likes.size(0)\n#                 val_correct += predicted.eq(likes).sum().item()\n\n#         val_loss /= len(val_loader)\n#         val_acc = val_correct / val_total\n\n#         print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n\n#     return model","metadata":{"execution":{"iopub.status.busy":"2024-10-07T19:44:18.071995Z","iopub.execute_input":"2024-10-07T19:44:18.072387Z","iopub.status.idle":"2024-10-07T19:44:18.095987Z","shell.execute_reply.started":"2024-10-07T19:44:18.072351Z","shell.execute_reply":"2024-10-07T19:44:18.094991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(train_images[0])","metadata":{"execution":{"iopub.status.busy":"2024-10-07T19:42:38.553879Z","iopub.execute_input":"2024-10-07T19:42:38.554271Z","iopub.status.idle":"2024-10-07T19:42:38.560757Z","shell.execute_reply.started":"2024-10-07T19:42:38.554233Z","shell.execute_reply":"2024-10-07T19:42:38.559703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Assume image_data is a list of binary image data and likes is a list of corresponding like counts\n# # image_data, likes = load_data()  # You need to implement this function to load your data\n\n# # Split the data\n# # train_images, val_images, train_likes, val_likes = train_test_split(image_data, likes, test_size=0.2, random_state=42)\n\n# # Define transformations\n# transform = transforms.Compose([\n#     transforms.Resize((224, 224)),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n# ])\n\n# # Create datasets\n# train_dataset = OptimizedImageLikesDataset(train_images, train_likes, transform=transform)\n# val_dataset = OptimizedImageLikesDataset(val_images, val_likes, transform=transform)\n\n# # Create data loaders\n# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, worker_init_fn=worker_init_fn)\n# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, worker_init_fn=worker_init_fn)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T19:44:21.385956Z","iopub.execute_input":"2024-10-07T19:44:21.386356Z","iopub.status.idle":"2024-10-07T19:44:21.701685Z","shell.execute_reply.started":"2024-10-07T19:44:21.386317Z","shell.execute_reply":"2024-10-07T19:44:21.700794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Initialize the model\n# model = LikesPredictionModel()\n\n# # Define loss function and optimizer\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T19:44:24.70881Z","iopub.execute_input":"2024-10-07T19:44:24.709204Z","iopub.status.idle":"2024-10-07T19:44:24.999219Z","shell.execute_reply.started":"2024-10-07T19:44:24.709166Z","shell.execute_reply":"2024-10-07T19:44:24.998386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Train the model\n# trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=2)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T19:44:26.891254Z","iopub.execute_input":"2024-10-07T19:44:26.891662Z","iopub.status.idle":"2024-10-07T19:44:28.562283Z","shell.execute_reply.started":"2024-10-07T19:44:26.891624Z","shell.execute_reply":"2024-10-07T19:44:28.560573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n# from efficientnet_pytorch import EfficientNet\nimport numpy as np\nfrom PIL import Image\nimport io\nfrom sklearn.model_selection import train_test_split\nimport timm\nfrom tqdm.auto import tqdm\n\nclass ImageLikesDataset(Dataset):\n    def __init__(self, image_data, likes, transform=None):\n        self.image_data = image_data\n        self.likes = likes\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_data)\n\n    def __getitem__(self, idx):\n        image = Image.open(io.BytesIO(self.image_data[idx])).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, torch.tensor(self.likes[idx], dtype=torch.long)\n\nclass LikesPredictionModel(nn.Module):\n    def __init__(self):\n        super(LikesPredictionModel, self).__init__()\n        self.effnet = timm.create_model('efficientnet_b0', pretrained=True)\n#         self.model = nn.Sequential(\n#             nn.Linear(1000,512),\n#             nn.BatchNorm1d(512),\n#             nn.ReLU(),\n#             nn.Linear(512,512),\n#             nn.BatchNorm1d(512),\n#             nn.ReLU(),\n#             nn.Linear(512,512),\n#             nn.BatchNorm1d(512),\n#             nn.ReLU(),\n#             nn.Linear(512,10)\n#         )\n#         for p in self.effnet.parameters\n#         self.fc1 = nn.Linear(1000, 512)\n# #         self.dropout = nn.Dropout(0.7)\n#         self.fc2 = nn.Linear(512, 10)\n#         self.bn1 = nn.BatchNorm1d(1000)\n#         self.bn2 = nn.BatchNorm1d(512)\n\n    def forward(self, x):\n        x = self.effnet(x)\n#         x = torch.relu((self.bn1(self.fc1(x))))\n#         x = torch.relu((self.bn1(self.fc1(x))))\n#         x = self.fc2(x)\n#         x = self.bn2((x))\n#         x = self.model(x)\n        return x.squeeze()\n\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=2):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(device)\n    model.to(device)\n    \n    for epoch in range(num_epochs):\n        print(f'epoch {epoch} running')\n        model.train()\n        train_loss = 0.0\n        y=[]\n        preds=[]\n        i=0\n        for images, likes in (tqdm(train_loader)):\n            if i%1000==0 : print(f'batch {i} running')\n            i+=1\n            y.extend(likes)\n            images, likes = images.to(device), likes.to(device)\n            outputs = model(images)\n            preds.extend(np.argmax(outputs.detach().cpu(),axis=1))\n            loss = criterion(outputs, likes)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n\n        train_loss /= len(train_loader)\n        train_acc = (np.array(y)==np.array(preds)).mean()\n        \n        model.eval()\n        val_loss = 0.0\n        y=[]\n        preds=[]\n        with torch.no_grad():\n            for images, likes in tqdm(val_loader):\n                y.extend(likes)\n                images, likes = images.to(device), likes.to(device)\n                outputs = model(images)\n                preds.extend(np.argmax(outputs.detach().cpu(),axis=1))\n                loss = criterion(outputs, likes)\n                val_loss += loss.item()\n            val_acc = (np.array(y)==np.array(preds)).mean()\n\n        val_loss /= len(val_loader)\n        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n\n    return model\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T06:57:41.640924Z","iopub.execute_input":"2024-10-10T06:57:41.64205Z","iopub.status.idle":"2024-10-10T06:57:41.666606Z","shell.execute_reply.started":"2024-10-10T06:57:41.642004Z","shell.execute_reply":"2024-10-10T06:57:41.665376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assume image_data is a list of binary image data and likes is a list of corresponding like counts\n# image_data, likes = load_data()  # You need to implement this function to load your data\n\n# Split the data\n# train_images, val_images, train_likes, val_likes = train_test_split(image_data, likes, test_size=0.2, random_state=42)\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Create datasets\ntrain_dataset = ImageLikesDataset(train_images, train_likes, transform=transform)\nval_dataset = ImageLikesDataset(val_images, val_likes, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T06:57:41.808887Z","iopub.execute_input":"2024-10-10T06:57:41.809279Z","iopub.status.idle":"2024-10-10T06:57:41.81612Z","shell.execute_reply.started":"2024-10-10T06:57:41.809243Z","shell.execute_reply":"2024-10-10T06:57:41.815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n\n# Initialize the model\nmodel = LikesPredictionModel()\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T06:57:42.023527Z","iopub.execute_input":"2024-10-10T06:57:42.023921Z","iopub.status.idle":"2024-10-10T06:57:42.308525Z","shell.execute_reply.started":"2024-10-10T06:57:42.023885Z","shell.execute_reply":"2024-10-10T06:57:42.307466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(image_data[0])","metadata":{"execution":{"iopub.status.busy":"2024-10-10T06:57:45.403458Z","iopub.execute_input":"2024-10-10T06:57:45.403878Z","iopub.status.idle":"2024-10-10T06:57:45.410952Z","shell.execute_reply.started":"2024-10-10T06:57:45.403842Z","shell.execute_reply":"2024-10-10T06:57:45.410005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Train the model\n# trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n\n# # Save the model\n# torch.save(trained_model.state_dict(), 'image_likes_model.pth')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-10T06:49:56.603828Z","iopub.execute_input":"2024-10-10T06:49:56.604603Z","iopub.status.idle":"2024-10-10T06:57:08.637239Z","shell.execute_reply.started":"2024-10-10T06:49:56.60456Z","shell.execute_reply":"2024-10-10T06:57:08.635847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_likes(model, image_dataloader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    preds = []\n    likess =[]\n    with torch.no_grad():\n        for images, likes in tqdm(image_dataloader):\n            likess.extend(likes)\n            images, likes = images.to(device), likes.to(device)\n            outputs = model(images)\n#             loss = criterion(outputs, likes)\n#             val_loss += loss.item() * images.size(0)\n            preds.extend((outputs.detach().cpu()))\n\n    return np.array(preds,dtype='f') ,np.array(likess,dtype='f')  # Convert back from log scale\n\n# Example usage\n# model = LikesPredictionModel()\n# model.load_state_dict(torch.load('image_likes_model.pth'))\n# predicted_likes = predict_likes(model, some_image_data)\n# print(f\"Predicted likes: {predicted_likes:.0f}\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-07T19:51:42.301447Z","iopub.execute_input":"2024-10-07T19:51:42.301905Z","iopub.status.idle":"2024-10-07T19:51:42.31099Z","shell.execute_reply.started":"2024-10-07T19:51:42.301866Z","shell.execute_reply":"2024-10-07T19:51:42.309955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_likes_v,likes_v = predict_likes(model, val_loader)\npredicted_likes_t,likes_t = predict_likes(model, train_loader)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-07T19:51:45.44064Z","iopub.execute_input":"2024-10-07T19:51:45.441139Z","iopub.status.idle":"2024-10-07T19:51:51.182351Z","shell.execute_reply.started":"2024-10-07T19:51:45.441091Z","shell.execute_reply":"2024-10-07T19:51:51.180754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, mean_squared_error\n\n# Instantiate the DecisionTreeClassifier\ndt_classifier = DecisionTreeClassifier()\n\n# Train the classifier\ndt_classifier.fit(predicted_likes_t, likes_t)\n\n# Make predictions on the validation data\nval_predictions = dt_classifier.predict(predicted_likes_v)\n\n# Evaluate the classifier\naccuracy = accuracy_score(likes_v, val_predictions)\nmse = mean_squared_error(likes_v, val_predictions)\n\nprint(f\"Validation Accuracy: {accuracy}\")\nprint(f\"Validation MSE: {mse}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, mean_squared_error\n\n# Instantiate the RandomForestClassifier\nrf_classifier = RandomForestClassifier()\n\n# Train the classifier\nrf_classifier.fit(predicted_likes_t, likes_t)\n\n# Make predictions on the validation data\nval_predictions = rf_classifier.predict(predicted_likes_v)\n\n# Evaluate the classifier\naccuracy = accuracy_score(likes_v, val_predictions)\nmse = mean_squared_error(likes_v, val_predictions)\n\nprint(f\"Validation Accuracy: {accuracy}\")\nprint(f\"Validation MSE: {mse}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.array(np.unique(predicted_likes, return_counts=True)).T","metadata":{"execution":{"iopub.status.busy":"2024-10-07T19:51:51.18538Z","iopub.execute_input":"2024-10-07T19:51:51.186547Z","iopub.status.idle":"2024-10-07T19:51:51.204625Z","shell.execute_reply.started":"2024-10-07T19:51:51.186476Z","shell.execute_reply":"2024-10-07T19:51:51.203455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.array(np.unique(likes, return_counts=True)).T","metadata":{"execution":{"iopub.status.busy":"2024-10-07T19:51:56.721687Z","iopub.execute_input":"2024-10-07T19:51:56.722096Z","iopub.status.idle":"2024-10-07T19:51:56.737473Z","shell.execute_reply.started":"2024-10-07T19:51:56.722059Z","shell.execute_reply":"2024-10-07T19:51:56.736562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# criterion(np.clip(predicted_likes,0,500000), likes)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:49:17.583671Z","iopub.execute_input":"2024-10-06T21:49:17.584154Z","iopub.status.idle":"2024-10-06T21:49:17.601022Z","shell.execute_reply.started":"2024-10-06T21:49:17.584105Z","shell.execute_reply":"2024-10-06T21:49:17.599901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.clip()","metadata":{},"execution_count":null,"outputs":[]}]}