{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d8c787",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-05T17:01:03.191268Z",
     "iopub.status.busy": "2024-10-05T17:01:03.190808Z",
     "iopub.status.idle": "2024-10-05T17:01:03.198392Z",
     "shell.execute_reply": "2024-10-05T17:01:03.197052Z"
    },
    "papermill": {
     "duration": 0.016845,
     "end_time": "2024-10-05T17:01:03.201503",
     "exception": false,
     "start_time": "2024-10-05T17:01:03.184658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1c7703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T17:01:03.211887Z",
     "iopub.status.busy": "2024-10-05T17:01:03.211413Z",
     "iopub.status.idle": "2024-10-05T17:01:04.275706Z",
     "shell.execute_reply": "2024-10-05T17:01:04.274239Z"
    },
    "papermill": {
     "duration": 1.072633,
     "end_time": "2024-10-05T17:01:04.278562",
     "exception": false,
     "start_time": "2024-10-05T17:01:03.205929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eaa8825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T17:01:04.289087Z",
     "iopub.status.busy": "2024-10-05T17:01:04.287899Z",
     "iopub.status.idle": "2024-10-05T17:01:04.293376Z",
     "shell.execute_reply": "2024-10-05T17:01:04.292332Z"
    },
    "papermill": {
     "duration": 0.013251,
     "end_time": "2024-10-05T17:01:04.295837",
     "exception": false,
     "start_time": "2024-10-05T17:01:04.282586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = '/kaggle/input/adobetraindata/behaviour_simulation_train.csv'\n",
    "test_path = '/kaggle/input/inter-iit-mid-prep-adobe/problem_1_test_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c05df52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T17:01:04.305706Z",
     "iopub.status.busy": "2024-10-05T17:01:04.305250Z",
     "iopub.status.idle": "2024-10-05T17:01:10.454467Z",
     "shell.execute_reply": "2024-10-05T17:01:10.453327Z"
    },
    "papermill": {
     "duration": 6.1576,
     "end_time": "2024-10-05T17:01:10.457408",
     "exception": false,
     "start_time": "2024-10-05T17:01:04.299808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a2200c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T17:01:10.467425Z",
     "iopub.status.busy": "2024-10-05T17:01:10.467024Z",
     "iopub.status.idle": "2024-10-05T17:01:10.658734Z",
     "shell.execute_reply": "2024-10-05T17:01:10.657430Z"
    },
    "papermill": {
     "duration": 0.200155,
     "end_time": "2024-10-05T17:01:10.661543",
     "exception": false,
     "start_time": "2024-10-05T17:01:10.461388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Photo_data = train_dataset[train_dataset['media'].apply(lambda x: x.startswith('[Photo'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b42e78b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T17:01:10.672024Z",
     "iopub.status.busy": "2024-10-05T17:01:10.671439Z",
     "iopub.status.idle": "2024-10-05T17:01:10.933101Z",
     "shell.execute_reply": "2024-10-05T17:01:10.931970Z"
    },
    "papermill": {
     "duration": 0.270697,
     "end_time": "2024-10-05T17:01:10.936256",
     "exception": false,
     "start_time": "2024-10-05T17:01:10.665559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_links = Photo_data['media'].apply(lambda x:x.split(\"Photo(previewUrl\")[1].split(\"'\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa9c74a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T17:01:10.946149Z",
     "iopub.status.busy": "2024-10-05T17:01:10.945713Z",
     "iopub.status.idle": "2024-10-05T17:05:59.323776Z",
     "shell.execute_reply": "2024-10-05T17:05:59.321531Z"
    },
    "papermill": {
     "duration": 288.389286,
     "end_time": "2024-10-05T17:05:59.329535",
     "exception": false,
     "start_time": "2024-10-05T17:01:10.940249",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download of 210009 images...\n",
      "Starting batch 0-10000\n",
      "Batch 0-10000: Downloaded 9766/10000 images\n",
      "Progress: 10000/210009 images\n",
      "Elapsed time: 11.39 seconds\n",
      "Estimated remaining time: 227.90 seconds\n",
      "Estimated total time: 239.29 seconds\n",
      "---\n",
      "Starting batch 10000-20000\n",
      "Batch 10000-20000: Downloaded 9755/10000 images\n",
      "Progress: 20000/210009 images\n",
      "Elapsed time: 22.97 seconds\n",
      "Estimated remaining time: 218.24 seconds\n",
      "Estimated total time: 241.21 seconds\n",
      "---\n",
      "Starting batch 20000-30000\n",
      "Batch 20000-30000: Downloaded 9761/10000 images\n",
      "Progress: 30000/210009 images\n",
      "Elapsed time: 34.16 seconds\n",
      "Estimated remaining time: 204.99 seconds\n",
      "Estimated total time: 239.15 seconds\n",
      "---\n",
      "Starting batch 30000-40000\n",
      "Batch 30000-40000: Downloaded 9759/10000 images\n",
      "Progress: 40000/210009 images\n",
      "Elapsed time: 45.34 seconds\n",
      "Estimated remaining time: 192.69 seconds\n",
      "Estimated total time: 238.02 seconds\n",
      "---\n",
      "Starting batch 40000-50000\n",
      "Batch 40000-50000: Downloaded 9746/10000 images\n",
      "Progress: 50000/210009 images\n",
      "Elapsed time: 56.66 seconds\n",
      "Estimated remaining time: 181.31 seconds\n",
      "Estimated total time: 237.96 seconds\n",
      "---\n",
      "Starting batch 50000-60000\n",
      "Batch 50000-60000: Downloaded 9739/10000 images\n",
      "Progress: 60000/210009 images\n",
      "Elapsed time: 68.36 seconds\n",
      "Estimated remaining time: 170.91 seconds\n",
      "Estimated total time: 239.27 seconds\n",
      "---\n",
      "Starting batch 60000-70000\n",
      "Batch 60000-70000: Downloaded 9759/10000 images\n",
      "Progress: 70000/210009 images\n",
      "Elapsed time: 79.93 seconds\n",
      "Estimated remaining time: 159.86 seconds\n",
      "Estimated total time: 239.79 seconds\n",
      "---\n",
      "Starting batch 70000-80000\n",
      "Batch 70000-80000: Downloaded 9768/10000 images\n",
      "Progress: 80000/210009 images\n",
      "Elapsed time: 91.11 seconds\n",
      "Estimated remaining time: 148.06 seconds\n",
      "Estimated total time: 239.16 seconds\n",
      "---\n",
      "Starting batch 80000-90000\n",
      "Batch 80000-90000: Downloaded 9729/10000 images\n",
      "Progress: 90000/210009 images\n",
      "Elapsed time: 102.41 seconds\n",
      "Estimated remaining time: 136.56 seconds\n",
      "Estimated total time: 238.98 seconds\n",
      "---\n",
      "Starting batch 90000-100000\n",
      "Batch 90000-100000: Downloaded 9756/10000 images\n",
      "Progress: 100000/210009 images\n",
      "Elapsed time: 113.98 seconds\n",
      "Estimated remaining time: 125.39 seconds\n",
      "Estimated total time: 239.37 seconds\n",
      "---\n",
      "Starting batch 100000-110000\n",
      "Batch 100000-110000: Downloaded 9771/10000 images\n",
      "Progress: 110000/210009 images\n",
      "Elapsed time: 126.16 seconds\n",
      "Estimated remaining time: 114.70 seconds\n",
      "Estimated total time: 240.86 seconds\n",
      "---\n",
      "Starting batch 110000-120000\n",
      "Batch 110000-120000: Downloaded 9744/10000 images\n",
      "Progress: 120000/210009 images\n",
      "Elapsed time: 137.76 seconds\n",
      "Estimated remaining time: 103.33 seconds\n",
      "Estimated total time: 241.09 seconds\n",
      "---\n",
      "Starting batch 120000-130000\n",
      "Batch 120000-130000: Downloaded 9737/10000 images\n",
      "Progress: 130000/210009 images\n",
      "Elapsed time: 149.15 seconds\n",
      "Estimated remaining time: 91.79 seconds\n",
      "Estimated total time: 240.94 seconds\n",
      "---\n",
      "Starting batch 130000-140000\n",
      "Batch 130000-140000: Downloaded 9737/10000 images\n",
      "Progress: 140000/210009 images\n",
      "Elapsed time: 160.58 seconds\n",
      "Estimated remaining time: 80.30 seconds\n",
      "Estimated total time: 240.88 seconds\n",
      "---\n",
      "Starting batch 140000-150000\n",
      "Batch 140000-150000: Downloaded 9726/10000 images\n",
      "Progress: 150000/210009 images\n",
      "Elapsed time: 172.24 seconds\n",
      "Estimated remaining time: 68.91 seconds\n",
      "Estimated total time: 241.15 seconds\n",
      "---\n",
      "Starting batch 150000-160000\n",
      "Batch 150000-160000: Downloaded 9728/10000 images\n",
      "Progress: 160000/210009 images\n",
      "Elapsed time: 184.16 seconds\n",
      "Estimated remaining time: 57.56 seconds\n",
      "Estimated total time: 241.72 seconds\n",
      "---\n",
      "Starting batch 160000-170000\n",
      "Batch 160000-170000: Downloaded 9730/10000 images\n",
      "Progress: 170000/210009 images\n",
      "Elapsed time: 195.64 seconds\n",
      "Estimated remaining time: 46.04 seconds\n",
      "Estimated total time: 241.68 seconds\n",
      "---\n",
      "Starting batch 170000-180000\n",
      "Batch 170000-180000: Downloaded 9738/10000 images\n",
      "Progress: 180000/210009 images\n",
      "Elapsed time: 207.72 seconds\n",
      "Estimated remaining time: 34.63 seconds\n",
      "Estimated total time: 242.35 seconds\n",
      "---\n",
      "Starting batch 180000-190000\n",
      "Batch 180000-190000: Downloaded 9738/10000 images\n",
      "Progress: 190000/210009 images\n",
      "Elapsed time: 219.56 seconds\n",
      "Estimated remaining time: 23.12 seconds\n",
      "Estimated total time: 242.69 seconds\n",
      "---\n",
      "Starting batch 190000-200000\n",
      "Batch 190000-200000: Downloaded 9733/10000 images\n",
      "Progress: 200000/210009 images\n",
      "Elapsed time: 231.43 seconds\n",
      "Estimated remaining time: 11.58 seconds\n",
      "Estimated total time: 243.01 seconds\n",
      "---\n",
      "Starting batch 200000-210000\n",
      "Batch 200000-210000: Downloaded 9741/10000 images\n",
      "Progress: 210000/210009 images\n",
      "Elapsed time: 243.72 seconds\n",
      "Estimated remaining time: 0.01 seconds\n",
      "Estimated total time: 243.73 seconds\n",
      "---\n",
      "Starting batch 210000-210009\n",
      "Batch 210000-210009: Downloaded 9/9 images\n",
      "Progress: 210009/210009 images\n",
      "Elapsed time: 243.85 seconds\n",
      "Estimated remaining time: -0.00 seconds\n",
      "Estimated total time: 243.85 seconds\n",
      "---\n",
      "\n",
      "Download complete. Successfully downloaded 204670/210009 images.\n",
      "Estimated storage space: 12.72 GB\n",
      "\n",
      "Sample image info:\n",
      "Format: JPEG\n",
      "Size: (680, 680)\n",
      "Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import time\n",
    "import os\n",
    "import concurrent.futures\n",
    "\n",
    "# Apply the patch to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 10000\n",
    "CONCURRENT_REQUESTS = 100\n",
    "TOTAL_IMAGES = len(img_links)\n",
    "\n",
    "async def fetch_image(session, url, semaphore):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            async with session.get(url, timeout=30) as response:\n",
    "                if response.status == 200:\n",
    "                    return await response.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {url}: {str(e)}\")\n",
    "    return None\n",
    "\n",
    "async def download_batch(urls, start_index):\n",
    "    semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_image(session, url, semaphore) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "#         success_idx = [i for i,e in zip(idxs,results) if e is not None]\n",
    "        successful = sum(1 for r in results if r is not None)\n",
    "        print(f\"Batch {start_index}-{start_index+len(urls)}: Downloaded {successful}/{len(urls)} images\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "async def download_all_images(img_links):\n",
    "    start_time = time.time()\n",
    "    all_image_data = []\n",
    "#     all_image_index =[]\n",
    "    \n",
    "    for i in range(0, len(img_links), BATCH_SIZE):\n",
    "        batch = img_links[i:i+BATCH_SIZE]\n",
    "        print(f\"Starting batch {i}-{i+len(batch)}\")\n",
    "        batch_data = await download_batch(batch, i)\n",
    "        all_image_data.extend(batch_data)\n",
    "#         all_image_index.extend(idx_data)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        images_downloaded = i + len(batch)\n",
    "        avg_time_per_image = elapsed_time / images_downloaded\n",
    "        estimated_total_time = avg_time_per_image * TOTAL_IMAGES\n",
    "        estimated_remaining_time = estimated_total_time - elapsed_time\n",
    "        \n",
    "        print(f\"Progress: {images_downloaded}/{TOTAL_IMAGES} images\")\n",
    "        print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "        print(f\"Estimated remaining time: {estimated_remaining_time:.2f} seconds\")\n",
    "        print(f\"Estimated total time: {estimated_total_time:.2f} seconds\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    return all_image_data\n",
    "\n",
    "def estimate_storage_space(image_data):\n",
    "    total_size = sum(len(img) for img in image_data if img is not None)\n",
    "    size_gb = total_size / (1024 * 1024 * 1024)\n",
    "    return size_gb\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume img_links is your list of 300,000 image URLs\n",
    "#     img_links = [...] # Your list of image URLs here\n",
    "    \n",
    "    print(f\"Starting download of {len(img_links)} images...\")\n",
    "    image_data = asyncio.run(download_all_images(list(img_links)))\n",
    "    \n",
    "    successful_downloads = sum(1 for img in image_data if img is not None)\n",
    "    print(f\"\\nDownload complete. Successfully downloaded {successful_downloads}/{TOTAL_IMAGES} images.\")\n",
    "    \n",
    "    storage_space = estimate_storage_space(image_data)\n",
    "    print(f\"Estimated storage space: {storage_space:.2f} GB\")\n",
    "\n",
    "    print(\"\\nSample image info:\")\n",
    "    if image_data and image_data[0]:\n",
    "        sample_image = Image.open(BytesIO(image_data[0]))\n",
    "        print(f\"Format: {sample_image.format}\")\n",
    "        print(f\"Size: {sample_image.size}\")\n",
    "        print(f\"Mode: {sample_image.mode}\")\n",
    "    else:\n",
    "        print(\"No valid sample image found.\")\n",
    "    import pickle\n",
    "    with open('image_data.pkl','wb') as f:\n",
    "        pickle.dump(image_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc447adc",
   "metadata": {
    "papermill": {
     "duration": 0.006106,
     "end_time": "2024-10-05T17:05:59.344784",
     "exception": false,
     "start_time": "2024-10-05T17:05:59.338678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5817858,
     "sourceId": 9548807,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 303.0142,
   "end_time": "2024-10-05T17:06:02.980692",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-05T17:00:59.966492",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
