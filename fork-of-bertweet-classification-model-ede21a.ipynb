{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9548807,"sourceType":"datasetVersion","datasetId":5817858}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\nimport os\nimport random\nfrom sklearn.model_selection import GroupShuffleSplit, train_test_split\nfrom tqdm.notebook import tqdm_notebook as tqdm\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:09.748303Z","iopub.execute_input":"2024-10-15T15:24:09.748701Z","iopub.status.idle":"2024-10-15T15:24:09.758888Z","shell.execute_reply.started":"2024-10-15T15:24:09.748664Z","shell.execute_reply":"2024-10-15T15:24:09.757871Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7861b47cad90>"},"metadata":{}}]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:09.760853Z","iopub.execute_input":"2024-10-15T15:24:09.761525Z","iopub.status.idle":"2024-10-15T15:24:09.771071Z","shell.execute_reply.started":"2024-10-15T15:24:09.761478Z","shell.execute_reply":"2024-10-15T15:24:09.770097Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\nos.environ['TORCH_USE_CUDA_DSA'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:09.772226Z","iopub.execute_input":"2024-10-15T15:24:09.772567Z","iopub.status.idle":"2024-10-15T15:24:09.781002Z","shell.execute_reply.started":"2024-10-15T15:24:09.772522Z","shell.execute_reply":"2024-10-15T15:24:09.780132Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"feature_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\nfeature_model = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=2).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:09.783361Z","iopub.execute_input":"2024-10-15T15:24:09.783737Z","iopub.status.idle":"2024-10-15T15:24:12.501922Z","shell.execute_reply.started":"2024-10-15T15:24:09.783694Z","shell.execute_reply":"2024-10-15T15:24:12.501154Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(r\"/kaggle/input/adobetraindata/behaviour_simulation_train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:12.503002Z","iopub.execute_input":"2024-10-15T15:24:12.503308Z","iopub.status.idle":"2024-10-15T15:24:15.271093Z","shell.execute_reply.started":"2024-10-15T15:24:12.503276Z","shell.execute_reply":"2024-10-15T15:24:15.270037Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def generate_prompt(row):\n    prompt = f\"Following is the information about Twitter post. \"\n\n    data_description = (f\"Text content: {row['content']}, \" \n                       f\"Inferred company: {row['inferred company']}, \" \n                       f\"Username: {row['username']}, \" \n                       f\"Date and time: {row['date']}\" \n                   )\n    prompt += data_description\n    return prompt","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:15.272445Z","iopub.execute_input":"2024-10-15T15:24:15.272844Z","iopub.status.idle":"2024-10-15T15:24:15.278783Z","shell.execute_reply.started":"2024-10-15T15:24:15.272799Z","shell.execute_reply":"2024-10-15T15:24:15.277729Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"df['prompt'] = df.apply(generate_prompt, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:15.280403Z","iopub.execute_input":"2024-10-15T15:24:15.280773Z","iopub.status.idle":"2024-10-15T15:24:22.573490Z","shell.execute_reply.started":"2024-10-15T15:24:15.280731Z","shell.execute_reply":"2024-10-15T15:24:22.572291Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"bins = [0, 10000, 100000000]\nlikes_binned_labels = [f'{bins[i]}-{bins[i + 1]}' for i in range(len(bins) - 2)]\nlikes_binned_labels.append('10000+')\n\n# Create binned column\ndf['likes_binned'] = pd.cut(df['likes'], bins=bins, labels=likes_binned_labels, include_lowest=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:22.574836Z","iopub.execute_input":"2024-10-15T15:24:22.575157Z","iopub.status.idle":"2024-10-15T15:24:22.589718Z","shell.execute_reply.started":"2024-10-15T15:24:22.575123Z","shell.execute_reply":"2024-10-15T15:24:22.589029Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"print(df['likes_binned'].value_counts(normalize=True).sort_index())","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:22.592646Z","iopub.execute_input":"2024-10-15T15:24:22.592957Z","iopub.status.idle":"2024-10-15T15:24:22.601465Z","shell.execute_reply.started":"2024-10-15T15:24:22.592922Z","shell.execute_reply":"2024-10-15T15:24:22.600596Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"likes_binned\n0-10000    0.987537\n10000+     0.012463\nName: proportion, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_fraction = 0.01\ndf_small, _ = train_test_split(df, test_size=1-sample_fraction,shuffle=True,random_state=42, stratify=df['likes_binned'])\ndf_small = df_small.reset_index(drop=1)\nprint(df_small['likes_binned'].value_counts(normalize=True))","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:22.602556Z","iopub.execute_input":"2024-10-15T15:24:22.603310Z","iopub.status.idle":"2024-10-15T15:24:23.111668Z","shell.execute_reply.started":"2024-10-15T15:24:22.603264Z","shell.execute_reply":"2024-10-15T15:24:23.110696Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"likes_binned\n0-10000    0.987667\n10000+     0.012333\nName: proportion, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"df = df_small","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.112869Z","iopub.execute_input":"2024-10-15T15:24:23.113189Z","iopub.status.idle":"2024-10-15T15:24:23.135716Z","shell.execute_reply.started":"2024-10-15T15:24:23.113156Z","shell.execute_reply":"2024-10-15T15:24:23.134731Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"class FeatureDataset(nn.Module):\n    def __init__(self, li):\n        super().__init__()\n        self.li = li\n        \n    def __len__(self):\n        return len(self.li)\n    \n    def __getitem__(self, index):\n        return {\n            'id' : self.li[index][0],\n            'text' : self.li[index][1]\n        }","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.137192Z","iopub.execute_input":"2024-10-15T15:24:23.137625Z","iopub.status.idle":"2024-10-15T15:24:23.146049Z","shell.execute_reply.started":"2024-10-15T15:24:23.137549Z","shell.execute_reply":"2024-10-15T15:24:23.145165Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def get_one_hot_encoding(s):\n    one_hot = [s==label for label in likes_binned_labels]\n    return np.array(one_hot, dtype=np.float32)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.147239Z","iopub.execute_input":"2024-10-15T15:24:23.149506Z","iopub.status.idle":"2024-10-15T15:24:23.155449Z","shell.execute_reply.started":"2024-10-15T15:24:23.149467Z","shell.execute_reply":"2024-10-15T15:24:23.154690Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\nmemory_allocated = torch.cuda.memory_allocated(device) / (1024**3)  \nmemory_reserved = torch.cuda.memory_reserved(device) / (1024**3) \n\nprint(f\"Memory Allocated: {memory_allocated:.2f} GB\")\nprint(f\"Memory Reserved: {memory_reserved:.2f} GB\")","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.156501Z","iopub.execute_input":"2024-10-15T15:24:23.156807Z","iopub.status.idle":"2024-10-15T15:24:23.228142Z","shell.execute_reply.started":"2024-10-15T15:24:23.156777Z","shell.execute_reply":"2024-10-15T15:24:23.227057Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Memory Allocated: 3.03 GB\nMemory Reserved: 3.15 GB\n","output_type":"stream"}]},{"cell_type":"code","source":"class dataset(nn.Module): \n    def __init__(self, li): \n        self.li = li\n  \n    def __len__(self): \n        return len(self.li)\n  \n    def __getitem__(self, index):\n        x, y = self.li[index]\n        if y < 1000:\n            y = torch.tensor(1)\n        else:\n            y = torch.tensor(0)\n        return {\n            'prompt': x,\n            'likes_binned': y\n        }","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.229513Z","iopub.execute_input":"2024-10-15T15:24:23.230074Z","iopub.status.idle":"2024-10-15T15:24:23.242146Z","shell.execute_reply.started":"2024-10-15T15:24:23.230037Z","shell.execute_reply":"2024-10-15T15:24:23.241290Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"def make_split(li,group=None,normal=False, split_task='company'):\n    if normal==True:\n        train_li, val_li  = train_test_split(li, train_size = 0.8,shuffle=True,random_state=42,stratify=df_small['likes_binned'])\n    elif split_task=='company':\n        gss = GroupShuffleSplit(n_splits=2, train_size=.8, random_state=42)\n        train_idx, val_idx = next(gss.split(li,groups= df['inferred company']))\n        train_li, val_li = [e for i, e in enumerate(li) if i in train_idx] ,[e for i, e in enumerate(li) if i in val_idx]\n    elif split_task=='time':\n        Y = pd.to_datetime(df_small['date'])\n        li = [l for _, l in sorted(zip(Y, li))]\n        train_idx=len(li)*8//10\n        train_li, val_li = li[:train_idx] , li[train_idx:]\n    return train_li, val_li","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.243185Z","iopub.execute_input":"2024-10-15T15:24:23.243508Z","iopub.status.idle":"2024-10-15T15:24:23.252470Z","shell.execute_reply.started":"2024-10-15T15:24:23.243460Z","shell.execute_reply":"2024-10-15T15:24:23.251605Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"li = [(prompt, label) for prompt, label in tqdm(zip(df['prompt'], df['likes']))]","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.253466Z","iopub.execute_input":"2024-10-15T15:24:23.253752Z","iopub.status.idle":"2024-10-15T15:24:23.285874Z","shell.execute_reply.started":"2024-10-15T15:24:23.253722Z","shell.execute_reply":"2024-10-15T15:24:23.285024Z"},"trusted":true},"execution_count":68,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9e40916d9e243a68269006a18a80b23"}},"metadata":{}}]},{"cell_type":"code","source":"train_li, val_li= make_split(li)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.287004Z","iopub.execute_input":"2024-10-15T15:24:23.287291Z","iopub.status.idle":"2024-10-15T15:24:23.331466Z","shell.execute_reply.started":"2024-10-15T15:24:23.287260Z","shell.execute_reply":"2024-10-15T15:24:23.330742Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"train_data = dataset(train_li)\nval_data = dataset(val_li)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.332437Z","iopub.execute_input":"2024-10-15T15:24:23.332707Z","iopub.status.idle":"2024-10-15T15:24:23.336872Z","shell.execute_reply.started":"2024-10-15T15:24:23.332676Z","shell.execute_reply":"2024-10-15T15:24:23.335877Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"train_load = DataLoader(train_data, batch_size=32,shuffle=True, num_workers=4)\nval_load = DataLoader(val_data, batch_size=32, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.338278Z","iopub.execute_input":"2024-10-15T15:24:23.338680Z","iopub.status.idle":"2024-10-15T15:24:23.346494Z","shell.execute_reply.started":"2024-10-15T15:24:23.338636Z","shell.execute_reply":"2024-10-15T15:24:23.345728Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# Set up the optimizer\noptimizer = AdamW(feature_model.parameters(), lr=1e-4)\n\nbest_loss = float('inf')\n\n# Training loop\nepochs = 5\nfeature_model.train()\nfor epoch in range(epochs):\n    preds, true_labels = [], []\n    net_loss = 0.0\n    for data in tqdm(train_load):\n        prompt = data['prompt']\n        labels = data['likes_binned'].to(device)\n        optimizer.zero_grad()\n\n        encodings = feature_tokenizer(prompt, truncation=True, padding=True, max_length=128, return_tensors=\"pt\").to(device)\n        outputs = feature_model(input_ids=encodings['input_ids'], attention_mask=encodings['attention_mask'], labels=labels)\n        loss = outputs.loss\n        net_loss += loss.item()/len(train_load)\n        \n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n\n        preds.extend(predictions.cpu().numpy())\n        true_labels.extend(labels.cpu().numpy())\n        \n        loss.backward()\n        optimizer.step()\n        \n        del prompt, labels, encodings, outputs, loss\n\n    print(f\"Epoch {epoch + 1}, Training Loss: {net_loss}\")\n    accuracy = np.sum(true_labels == np.array(preds))/len(preds)\n    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n    \n    preds, true_labels = [], []\n    net_loss = 0.0\n    for data in tqdm(val_load):\n        prompt = data['prompt']\n        labels = data['likes_binned'].to(device)\n            \n        with torch.no_grad():\n            encodings = feature_tokenizer(prompt, truncation=True, padding=True, max_length=128, return_tensors=\"pt\").to(device)\n            outputs = feature_model(input_ids=encodings['input_ids'], attention_mask=encodings['attention_mask'], labels=labels)\n            loss = outputs.loss\n            net_loss += loss.item()/len(val_load)\n            \n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n\n        preds.extend(predictions.cpu().numpy())\n        true_labels.extend(labels.cpu().numpy())\n        \n        del prompt, labels, encodings, outputs, loss\n            \n    print(f\"Epoch {epoch + 1}, Validation Loss: {net_loss}\")\n    accuracy = np.sum(true_labels == np.array(preds))/len(preds)\n    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n    if(net_loss < best_loss):\n        print(\"Model Saved\")\n        best_loss = net_loss\n        feature_model.save_pretrained(\"/kaggle/working/bert_classifier_model\")","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:24:23.347920Z","iopub.execute_input":"2024-10-15T15:24:23.348286Z","iopub.status.idle":"2024-10-15T15:27:27.894932Z","shell.execute_reply.started":"2024-10-15T15:24:23.348245Z","shell.execute_reply":"2024-10-15T15:27:27.893774Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/84 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7c2658af6c84680930c95cab222c09c"}},"metadata":{}},{"name":"stdout","text":"Epoch 1, Training Loss: 0.40129729892526356\nAccuracy: 86.09%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13ae49026bd34d88b26503370421305a"}},"metadata":{}},{"name":"stdout","text":"Epoch 1, Validation Loss: 0.32993098822506994\nAccuracy: 90.29%\nModel Saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/84 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7278f40a6ee41d0ba75747813b001c4"}},"metadata":{}},{"name":"stdout","text":"Epoch 2, Training Loss: 0.3177593335331904\nAccuracy: 86.77%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c5e4406c8234514901879223eda1243"}},"metadata":{}},{"name":"stdout","text":"Epoch 2, Validation Loss: 0.374344144355167\nAccuracy: 90.29%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/84 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59231b045c03485a9f7524b209fd4966"}},"metadata":{}},{"name":"stdout","text":"Epoch 3, Training Loss: 0.2735531255602836\nAccuracy: 89.25%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efbbb7cc805344859e9ade9767edd43d"}},"metadata":{}},{"name":"stdout","text":"Epoch 3, Validation Loss: 0.6038504242897033\nAccuracy: 87.65%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/84 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbae45f1c87341d4b4b3076ca8f40976"}},"metadata":{}},{"name":"stdout","text":"Epoch 4, Training Loss: 0.4015017217468648\nAccuracy: 86.69%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a6ba5ea1bb94aceaa207d3fd4e97fb6"}},"metadata":{}},{"name":"stdout","text":"Epoch 4, Validation Loss: 0.3230961696668105\nAccuracy: 90.29%\nModel Saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/84 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4138779b90794dc79bf80529efe9ea9d"}},"metadata":{}},{"name":"stdout","text":"Epoch 5, Training Loss: 0.4035429254706416\nAccuracy: 86.69%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed886c5f72694c428e30273a2648303d"}},"metadata":{}},{"name":"stdout","text":"Epoch 5, Validation Loss: 0.3281292508948933\nAccuracy: 90.29%\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/bert_classifier_model\", num_labels=2).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:27:27.896800Z","iopub.execute_input":"2024-10-15T15:27:27.897259Z","iopub.status.idle":"2024-10-15T15:27:28.167431Z","shell.execute_reply.started":"2024-10-15T15:27:27.897190Z","shell.execute_reply":"2024-10-15T15:27:28.166609Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"preds, true_labels = [], []\nnet_loss = 0.0\nfor batch in tqdm(val_load):\n    prompt = data['prompt']\n    labels = data['likes_binned'].to(device)\n            \n    with torch.no_grad():\n        encodings = feature_tokenizer(prompt, truncation=True, padding=True, max_length=128, return_tensors=\"pt\").to(device)\n        outputs = best_model(input_ids=encodings['input_ids'], attention_mask=encodings['attention_mask'], labels=labels)\n        loss = outputs.loss\n        net_loss += loss.item()/len(val_load)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n\n    preds.extend(predictions.cpu().numpy())\n    true_labels.extend(labels.cpu().numpy())\n\nprint(f\"Val Loss: {net_loss}\")\n# Calculate accuracy or other metrics suitable for multiclass classification\naccuracy = np.sum(true_labels == np.array(preds))/len(preds)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:27:28.172178Z","iopub.execute_input":"2024-10-15T15:27:28.172474Z","iopub.status.idle":"2024-10-15T15:27:29.399025Z","shell.execute_reply.started":"2024-10-15T15:27:28.172444Z","shell.execute_reply":"2024-10-15T15:27:29.397812Z"},"trusted":true},"execution_count":74,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"228a614540884180a0c50e3cfb6c378f"}},"metadata":{}},{"name":"stdout","text":"Val Loss: 0.23001472651958466\nAccuracy: 95.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"preds, true_labels = [], []\nnet_loss = 0.0\nfor batch in tqdm(train_load):\n    prompt = data['prompt']\n    labels = data['likes_binned'].to(device)\n            \n    with torch.no_grad():\n        encodings = feature_tokenizer(prompt, truncation=True, padding=True, max_length=128, return_tensors=\"pt\").to(device)\n        outputs = best_model(input_ids=encodings['input_ids'], attention_mask=encodings['attention_mask'], labels=labels)\n        loss = outputs.loss\n        net_loss += loss.item()/len(train_load)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n\n    preds.extend(predictions.cpu().numpy())\n    true_labels.extend(labels.cpu().numpy())\n\nprint(f\"Train Loss: {net_loss}\")\n# Calculate accuracy or other metrics suitable for multiclass classification\naccuracy = np.sum(true_labels == np.array(preds))/len(preds)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:27:29.400653Z","iopub.execute_input":"2024-10-15T15:27:29.400965Z","iopub.status.idle":"2024-10-15T15:27:36.961481Z","shell.execute_reply.started":"2024-10-15T15:27:29.400928Z","shell.execute_reply":"2024-10-15T15:27:36.960438Z"},"trusted":true},"execution_count":75,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/84 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5999bae261b740d5a220fb8cfd0189df"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.23001472651958427\nAccuracy: 95.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(feature_model, 'bertclassifiermodel.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:27:36.963113Z","iopub.execute_input":"2024-10-15T15:27:36.963466Z","iopub.status.idle":"2024-10-15T15:27:37.806305Z","shell.execute_reply.started":"2024-10-15T15:27:36.963421Z","shell.execute_reply":"2024-10-15T15:27:37.805460Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLinks\nFileLinks(r'/kaggle/working/bert_classifier_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:27:37.807742Z","iopub.execute_input":"2024-10-15T15:27:37.808636Z","iopub.status.idle":"2024-10-15T15:27:37.815808Z","shell.execute_reply.started":"2024-10-15T15:27:37.808589Z","shell.execute_reply":"2024-10-15T15:27:37.814871Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"","text/html":"Path (<tt>/kaggle/working/bert_classifier_model.pth</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."},"metadata":{}}]},{"cell_type":"code","source":"feature_model.save_pretrained(\"/kaggle/working/bert_classifier_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:27:37.817001Z","iopub.execute_input":"2024-10-15T15:27:37.817329Z","iopub.status.idle":"2024-10-15T15:27:39.017029Z","shell.execute_reply.started":"2024-10-15T15:27:37.817296Z","shell.execute_reply":"2024-10-15T15:27:39.016000Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"feature_tokenizer.save_pretrained(\"/kaggle/working/bert_classifier_tokenizer.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-10-15T15:27:39.018390Z","iopub.execute_input":"2024-10-15T15:27:39.018705Z","iopub.status.idle":"2024-10-15T15:27:39.028416Z","shell.execute_reply.started":"2024-10-15T15:27:39.018672Z","shell.execute_reply":"2024-10-15T15:27:39.027471Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/bert_classifier_tokenizer.pth/tokenizer_config.json',\n '/kaggle/working/bert_classifier_tokenizer.pth/special_tokens_map.json',\n '/kaggle/working/bert_classifier_tokenizer.pth/vocab.txt',\n '/kaggle/working/bert_classifier_tokenizer.pth/bpe.codes',\n '/kaggle/working/bert_classifier_tokenizer.pth/added_tokens.json')"},"metadata":{}}]}]}